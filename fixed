"""
Microsoft Teams Call Quality Analysis System
This system analyzes poor quality Teams calls and provides remediation recommendations.
"""

import os
import json
import logging
from typing import Dict, List, Any, TypedDict
from dotenv import load_dotenv
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.core.exceptions import AzureError
from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI
from langchain_community.vectorstores.azuresearch import AzureSearch
from langgraph.graph import StateGraph, END

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

class GraphState(TypedDict):
    """Type definition for the graph state"""
    alert: Dict[str, Any]
    call_id: str
    user_id: str
    call_docs: List[Dict[str, Any]]
    user_context_docs: List[Dict[str, Any]]
    final_prompt: str
    insights: Dict[str, Any]

def validate_env_variables() -> bool:
    """Validate all required environment variables are present"""
    required_vars = [
        "AZURE_SEARCH_ENDPOINT",
        "AZURE_SEARCH_KEY", 
        "AZURE_SEARCH_INDEX",
        "AZURE_OPENAI_API_BASE",
        "AZURE_OPENAI_API_KEY",
        "AZURE_OPENAI_DEPLOYMENT",
        "AZURE_OPENAI_API_VERSION"
    ]
    
    missing_vars = []
    for var in required_vars:
        if not os.getenv(var):
            missing_vars.append(var)
    
    if missing_vars:
        logger.error(f"Missing required environment variables: {missing_vars}")
        return False
    
    logger.info("‚úÖ All environment variables validated")
    return True

def create_azure_search_client() -> SearchClient:
    """Create Azure Search client with proper error handling"""
    try:
        search_credential = AzureKeyCredential(os.getenv("AZURE_SEARCH_KEY"))
        client = SearchClient(
            endpoint=os.getenv("AZURE_SEARCH_ENDPOINT"),
            index_name=os.getenv("AZURE_SEARCH_INDEX"),
            credential=search_credential
        )
        logger.info("‚úÖ Azure Search client created successfully")
        return client
    except Exception as e:
        logger.error(f"‚ùå Failed to create Azure Search client: {e}")
        raise

def create_azure_openai_client() -> AzureChatOpenAI:
    """Create Azure OpenAI client with proper error handling"""
    try:
        client = AzureChatOpenAI(
            azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
            openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_API_BASE"),
            openai_api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            temperature=0
        )
        logger.info("‚úÖ Azure OpenAI client created successfully")
        return client
    except Exception as e:
        logger.error(f"‚ùå Failed to create Azure OpenAI client: {e}")
        raise

def create_embeddings_client() -> AzureOpenAIEmbeddings:
    """Create Azure OpenAI embeddings client"""
    try:
        client = AzureOpenAIEmbeddings(
            azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
            openai_api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_API_BASE"),
            openai_api_key=os.getenv("AZURE_OPENAI_API_KEY")
        )
        logger.info("‚úÖ Azure OpenAI embeddings client created successfully")
        return client
    except Exception as e:
        logger.error(f"‚ùå Failed to create embeddings client: {e}")
        raise

# -------- LangGraph Node Functions -------- #

def load_alert_node(state: GraphState) -> GraphState:
    """Load alert data from JSON file"""
    logger.info("üì• Loading alert data...")
    
    try:
        alert_file = "alert.json"
        if not os.path.exists(alert_file):
            logger.error(f"‚ùå Alert file '{alert_file}' not found")
            state["alert"] = {}
            state["call_id"] = ""
            state["user_id"] = ""
            return state
        
        with open(alert_file, 'r', encoding='utf-8') as f:
            alert = json.load(f)
        
        state["alert"] = alert
        state["call_id"] = alert.get("call_id", "")
        state["user_id"] = alert.get("User", {}).get("email", "")
        
        logger.info(f"‚úÖ Alert loaded - Call ID: {state['call_id']}, User: {state['user_id']}")
        
    except json.JSONDecodeError as e:
        logger.error(f"‚ùå Invalid JSON in alert file: {e}")
        state["alert"] = {}
        state["call_id"] = ""
        state["user_id"] = ""
    except Exception as e:
        logger.error(f"‚ùå Error loading alert: {e}")
        state["alert"] = {}
        state["call_id"] = ""
        state["user_id"] = ""
    
    return state

def fetch_call_node(state: GraphState) -> GraphState:
    """Fetch call documents from Azure Search"""
    logger.info("üîç Fetching call documents...")
    
    try:
        call_id = state.get("call_id", "")
        if not call_id:
            logger.warning("‚ö†Ô∏è No call_id available")
            state["call_docs"] = []
            return state
        
        search_client = create_azure_search_client()
        search_query = f"sessions_segments_callId:{call_id}"
        
        results = search_client.search(
            search_text=search_query,
            top=10,
            select=["*"]
        )
        
        # Convert search results to serializable format
        call_docs = []
        for doc in results:
            if isinstance(doc, dict):
                call_docs.append(doc)
            else:
                # Convert search result object to dict
                doc_dict = {}
                for key in doc.keys():
                    doc_dict[key] = doc[key]
                call_docs.append(doc_dict)
        
        state["call_docs"] = call_docs
        logger.info(f"‚úÖ Found {len(call_docs)} call documents")
        
    except AzureError as e:
        logger.error(f"‚ùå Azure Search error: {e}")
        state["call_docs"] = []
    except Exception as e:
        logger.error(f"‚ùå Error fetching call data: {e}")
        state["call_docs"] = []
    
    return state

def fetch_user_context_node(state: GraphState) -> GraphState:
    """Fetch user context documents from Azure Search"""
    logger.info("üë§ Fetching user context...")
    
    try:
        user_id = state.get("user_id", "")
        if not user_id:
            logger.warning("‚ö†Ô∏è No user_id available")
            state["user_context_docs"] = []
            return state
        
        search_client = create_azure_search_client()
        search_query = f"participants_user_displayName:{user_id} OR organizer_user_displayName:{user_id}"
        
        results = search_client.search(
            search_text=search_query,
            top=5,
            select=["*"]
        )
        
        # Convert search results to serializable format
        context_docs = []
        for doc in results:
            if isinstance(doc, dict):
                context_docs.append(doc)
            else:
                # Convert search result object to dict
                doc_dict = {}
                for key in doc.keys():
                    doc_dict[key] = doc[key]
                context_docs.append(doc_dict)
        
        state["user_context_docs"] = context_docs
        logger.info(f"‚úÖ Found {len(context_docs)} user context documents")
        
    except AzureError as e:
        logger.error(f"‚ùå Azure Search error: {e}")
        state["user_context_docs"] = []
    except Exception as e:
        logger.error(f"‚ùå Error fetching user context: {e}")
        state["user_context_docs"] = []
    
    return state

def build_prompt_node(state: GraphState) -> GraphState:
    """Build the analysis prompt for the LLM"""
    logger.info("üìù Building analysis prompt...")
    
    try:
        alert = state.get("alert", {})
        current = state.get("call_docs", [])
        history = state.get("user_context_docs", [])
        user_email = alert.get("User", {}).get("email", "unknown")
        
        prompt = f"""You are a Microsoft Teams network engineer analyzing a poor quality call.

TASK:
1. Analyze the call records and CDR metrics across participants and sessions
2. Identify the most likely root cause of the poor Teams call quality
3. Provide 5 technically realistic actions a network administrator could take to fix the issue
4. Choose and return the single most important action to take first

ALERT DATA:
{json.dumps(alert, indent=2)}

CURRENT CALL DATA ({len(current)} documents):
{json.dumps(current, indent=2)}

HISTORICAL USER CONTEXT ({len(history)} documents for {user_email}):
{json.dumps(history, indent=2)}

RESPONSE FORMAT (MUST BE VALID JSON):
{{
  "root_cause": "Brief technical summary of the root cause",
  "recommendations": [
    "Specific action 1",
    "Specific action 2", 
    "Specific action 3",
    "Specific action 4",
    "Specific action 5"
  ],
  "chosen_action": "The most critical action from the recommendations list"
}}

Important: Respond ONLY with the JSON object, no additional text."""

        state["final_prompt"] = prompt
        logger.info("‚úÖ Analysis prompt built successfully")
        
    except Exception as e:
        logger.error(f"‚ùå Error building prompt: {e}")
        state["final_prompt"] = ""
    
    return state

def llm_analysis_node(state: GraphState) -> GraphState:
    """Analyze the data using Azure OpenAI"""
    logger.info("ü§ñ Running LLM analysis...")
    
    try:
        prompt = state.get("final_prompt", "")
        if not prompt:
            logger.error("‚ùå No prompt available for analysis")
            state["insights"] = {"error": "No prompt available"}
            return state
        
        llm = create_azure_openai_client()
        
        # Use invoke method for chat models
        response = llm.invoke(prompt)
        
        # Extract content from response
        if hasattr(response, 'content'):
            response_text = response.content
        else:
            response_text = str(response)
        
        logger.info("‚úÖ LLM response received")
        
        # Parse JSON response
        try:
            insights = json.loads(response_text.strip())
            state["insights"] = insights
            logger.info("‚úÖ LLM response parsed successfully")
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Failed to parse LLM response as JSON: {e}")
            state["insights"] = {
                "error": f"JSON parsing failed: {str(e)}",
                "raw_response": response_text
            }
            
    except Exception as e:
        logger.error(f"‚ùå Error in LLM analysis: {e}")
        state["insights"] = {
            "error": f"LLM analysis failed: {str(e)}",
            "raw_response": ""
        }
    
    return state

def print_output_node(state: GraphState) -> GraphState:
    """Print the final analysis results"""
    logger.info("üìã Generating final output...")
    
    print("\n" + "="*60)
    print("üîç TEAMS CALL QUALITY ANALYSIS RESULTS")
    print("="*60)
    
    insights = state.get("insights", {})
    
    if "error" in insights:
        print(f"‚ùå Analysis Error: {insights['error']}")
        if "raw_response" in insights:
            print(f"Raw Response: {insights['raw_response']}")
    else:
        print(f"üéØ Root Cause: {insights.get('root_cause', 'Not identified')}")
        print(f"\nüí° Recommendations:")
        for i, rec in enumerate(insights.get('recommendations', []), 1):
            print(f"   {i}. {rec}")
        print(f"\nüöÄ Priority Action: {insights.get('chosen_action', 'Not specified')}")
    
    print("="*60)
    print(f"üìä Analysis Summary:")
    print(f"   ‚Ä¢ Alert processed: {bool(state.get('alert'))}")
    print(f"   ‚Ä¢ Call documents: {len(state.get('call_docs', []))}")
    print(f"   ‚Ä¢ User context docs: {len(state.get('user_context_docs', []))}")
    print("="*60)
    
    return state

def create_workflow_graph() -> StateGraph:
    """Create and configure the LangGraph workflow"""
    logger.info("üèóÔ∏è Creating workflow graph...")
    
    # Create the state graph
    graph = StateGraph(GraphState)
    
    # Add nodes
    graph.add_node("load_alert", load_alert_node)
    graph.add_node("fetch_call", fetch_call_node)
    graph.add_node("fetch_user_context", fetch_user_context_node)
    graph.add_node("build_prompt", build_prompt_node)
    graph.add_node("llm_analysis", llm_analysis_node)
    graph.add_node("print_output", print_output_node)
    
    # Set entry point
    graph.set_entry_point("load_alert")
    
    # Define the workflow edges
    graph.add_edge("load_alert", "fetch_call")
    graph.add_edge("fetch_call", "fetch_user_context")
    graph.add_edge("fetch_user_context", "build_prompt")
    graph.add_edge("build_prompt", "llm_analysis")
    graph.add_edge("llm_analysis", "print_output")
    graph.add_edge("print_output", END)
    
    logger.info("‚úÖ Workflow graph created successfully")
    return graph

def create_sample_alert_file():
    """Create a sample alert.json file for testing"""
    sample_alert = {
        "call_id": "sample_call_123",
        "timestamp": "2024-01-15T10:30:00Z",
        "User": {
            "email": "user@company.com",
            "displayName": "John Doe"
        },
        "quality_metrics": {
            "audio_quality": "poor",
            "video_quality": "fair",
            "overall_rating": 2
        },
        "network_metrics": {
            "packet_loss": 0.05,
            "latency": 150,
            "jitter": 30
        }
    }
    
    with open("alert.json", "w", encoding="utf-8") as f:
        json.dump(sample_alert, f, indent=2)
    
    logger.info("‚úÖ Sample alert.json file created")

def main():
    """Main execution function"""
    print("üöÄ Starting Microsoft Teams Call Quality Analysis System")
    print("="*60)
    
    try:
        # Validate environment
        if not validate_env_variables():
            print("‚ùå Environment validation failed. Please check your .env file.")
            return False
        
        # Create sample alert file if it doesn't exist
        if not os.path.exists("alert.json"):
            logger.info("üìÑ Creating sample alert.json file...")
            create_sample_alert_file()
        
        # Create and compile the workflow
        graph = create_workflow_graph()
        app = graph.compile()
        
        # Execute the workflow
        logger.info("‚ñ∂Ô∏è Starting analysis workflow...")
        initial_state = {
            "alert": {},
            "call_id": "",
            "user_id": "",
            "call_docs": [],
            "user_context_docs": [],
            "final_prompt": "",
            "insights": {}
        }
        
        final_state = app.invoke(initial_state)
        
        logger.info("‚úÖ Analysis workflow completed successfully!")
        return True
        
    except Exception as e:
        logger.error(f"‚ùå Error in main execution: {e}")
        print(f"‚ùå System error: {e}")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nüéâ Analysis completed successfully!")
    else:
        print("\nüí• Analysis failed. Check the logs for details.")
